{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerry26432341/myTheses/blob/main/0609_%E6%A8%A1%E5%9E%8B%E5%BC%95%E5%85%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download zh_core_web_sm\n",
        "!wget -O chineseStopWords.txt https://raw.githubusercontent.com/tomlinNTUB/Machine-Learning-Basics/main/Chinese%20Stopwords.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlX5T0jNA2dI",
        "outputId": "be35eaad-55f6-43b4-a743-dd6b3ee2dde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.2\n",
            "    Uninstalling spacy-3.5.2:\n",
            "      Successfully uninstalled spacy-3.5.2\n",
            "Successfully installed spacy-3.5.3\n",
            "2023-06-08 13:02:24.553750: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-08 13:02:25.775357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting zh-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.5.0/zh_core_web_sm-3.5.0-py3-none-any.whl (48.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from zh-core-web-sm==3.5.0) (3.5.3)\n",
            "Collecting spacy-pkuseg<0.1.0,>=0.0.27 (from zh-core-web-sm==3.5.0)\n",
            "  Downloading spacy_pkuseg-0.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->zh-core-web-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: spacy-pkuseg, zh-core-web-sm\n",
            "Successfully installed spacy-pkuseg-0.0.32 zh-core-web-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('zh_core_web_sm')\n",
            "--2023-06-08 13:02:39--  https://raw.githubusercontent.com/tomlinNTUB/Machine-Learning-Basics/main/Chinese%20Stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-06-08 13:02:39 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jieba\n",
        "import re\n",
        "import gensim\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, vstack\n",
        "from sklearn.svm import LinearSVC\n",
        "from joblib import dump\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# 掛載Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNjCJf8kA7L9",
        "outputId": "a7a86138-a610-45cb-b596-ebedab473b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"在 cat 列中总共有 %d 个空值.\" % df['cat'].isnull().sum())\n",
        "print(\"在 review 列中总共有 %d 个空值.\" % df['review'].isnull().sum())\n",
        "df[df.isnull().values==True]\n",
        "df = df[pd.notnull(df['review'])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "wq8W0Wp1BLI0",
        "outputId": "d9c327cc-3373-4e37-bba5-c924cd31064d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4dbbd366e089>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"在 cat 列中总共有 %d 个空值.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"在 review 列中总共有 %d 个空值.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cat_id'] = df['cat'].factorize()[0]\n",
        "cat_id_df = df[['cat', 'cat_id']].drop_duplicates().sort_values('cat_id').reset_index(drop=True)\n",
        "cat_to_id = dict(cat_id_df.values)\n",
        "id_to_cat = dict(cat_id_df[['cat_id', 'cat']].values)\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "KFse98lsBcUr",
        "outputId": "d0c0b8ff-d747-458f-ed7a-523b8f2840dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       cat  label                                             review  cat_id  \\\n",
              "13445   平板      0  大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要...       1   \n",
              "54011   酒店      1  房间很干净。餐厅饭菜一般般。可惜没有独立的沙滩，需要步行一段路才能到海边。补充点评 2007...       9   \n",
              "50756  计算机      1  目前3k以下的笔记本很少有货的，这个相对来说还算可以。配置比较全，带摄像头，整体做工尚可，装...       8   \n",
              "32423  洗发水      0  东西用着跟以前买的不一样，洗发液很稀，而且不出泡沫。很失败的一次购物，一直都很信任京东， 这...       4   \n",
              "53448   酒店      1        位置很好，就在南京路步行街后面，逛街购物很方便，然后离人民广场地铁站也近，交通很方便。       9   \n",
              "11930   平板      0                                         刚下单就降价，不舒服       1   \n",
              "58065   酒店      0  看中的是离机场近早上530起有专车送。但是如果是晚上到达的话太不安全了 周围什么都没有 的士...       9   \n",
              "23981   水果      0  在这家买过好几次了，说实话，这是最后一次了。苹果越来越小，肯定没有10斤，也懒得计较了。为什...       3   \n",
              "51398  计算机      0  1发热厉害，用一个小时下面就烫手了，Dell的3000出头的笔记本一天也没这么热，有点害怕 ...       8   \n",
              "28942  洗发水      1                                   非常好的商品，物流也快很好的商品       4   \n",
              "\n",
              "                                         filtered_review  \n",
              "13445                    买 买 买 买 买 买 买 买 买 买 买 买 买 买 买 买  \n",
              "54011  房间 干净 餐厅 饭菜 般 可惜 独立 沙滩 步行 段 路 海边 补充 点评 2007年 1...  \n",
              "50756  3k 笔记本 少有 货 相对来说 还算 配置 全 摄像头 整体 做工 尚 装ghost版 系...  \n",
              "32423  东西 买 洗 发液 稀 泡沫 失败 次 购物 信任 京东 洗发液 真心 专业 鉴定 信口开河...  \n",
              "53448                        位置 南京 路步 行街 逛街 购物 广场 地铁站 交通  \n",
              "11930                                           下单 降价 舒服  \n",
              "58065  看中 机场 早上 专车 送 晚上 到达 太 的士 黑车 白天 没事 地铁站 走 想 搭乘 早...  \n",
              "23981  这家 买 好几 次 说 实话 这是 次 苹果 越来越 肯定 斤 懒得 计较 生意 做 回头客...  \n",
              "51398  发热 厉害 小时 烫手 Dell 出头 笔记本 天 热 害怕 2机器 感觉 挺 单薄 塑料感...  \n",
              "28942                                           商品 物流 商品  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a572e99b-3e90-4cd1-8982-ee74d0f797c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>filtered_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13445</th>\n",
              "      <td>平板</td>\n",
              "      <td>0</td>\n",
              "      <td>大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要买！大家不要...</td>\n",
              "      <td>1</td>\n",
              "      <td>买 买 买 买 买 买 买 买 买 买 买 买 买 买 买 买</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54011</th>\n",
              "      <td>酒店</td>\n",
              "      <td>1</td>\n",
              "      <td>房间很干净。餐厅饭菜一般般。可惜没有独立的沙滩，需要步行一段路才能到海边。补充点评 2007...</td>\n",
              "      <td>9</td>\n",
              "      <td>房间 干净 餐厅 饭菜 般 可惜 独立 沙滩 步行 段 路 海边 补充 点评 2007年 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50756</th>\n",
              "      <td>计算机</td>\n",
              "      <td>1</td>\n",
              "      <td>目前3k以下的笔记本很少有货的，这个相对来说还算可以。配置比较全，带摄像头，整体做工尚可，装...</td>\n",
              "      <td>8</td>\n",
              "      <td>3k 笔记本 少有 货 相对来说 还算 配置 全 摄像头 整体 做工 尚 装ghost版 系...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32423</th>\n",
              "      <td>洗发水</td>\n",
              "      <td>0</td>\n",
              "      <td>东西用着跟以前买的不一样，洗发液很稀，而且不出泡沫。很失败的一次购物，一直都很信任京东， 这...</td>\n",
              "      <td>4</td>\n",
              "      <td>东西 买 洗 发液 稀 泡沫 失败 次 购物 信任 京东 洗发液 真心 专业 鉴定 信口开河...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53448</th>\n",
              "      <td>酒店</td>\n",
              "      <td>1</td>\n",
              "      <td>位置很好，就在南京路步行街后面，逛街购物很方便，然后离人民广场地铁站也近，交通很方便。</td>\n",
              "      <td>9</td>\n",
              "      <td>位置 南京 路步 行街 逛街 购物 广场 地铁站 交通</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930</th>\n",
              "      <td>平板</td>\n",
              "      <td>0</td>\n",
              "      <td>刚下单就降价，不舒服</td>\n",
              "      <td>1</td>\n",
              "      <td>下单 降价 舒服</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58065</th>\n",
              "      <td>酒店</td>\n",
              "      <td>0</td>\n",
              "      <td>看中的是离机场近早上530起有专车送。但是如果是晚上到达的话太不安全了 周围什么都没有 的士...</td>\n",
              "      <td>9</td>\n",
              "      <td>看中 机场 早上 专车 送 晚上 到达 太 的士 黑车 白天 没事 地铁站 走 想 搭乘 早...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23981</th>\n",
              "      <td>水果</td>\n",
              "      <td>0</td>\n",
              "      <td>在这家买过好几次了，说实话，这是最后一次了。苹果越来越小，肯定没有10斤，也懒得计较了。为什...</td>\n",
              "      <td>3</td>\n",
              "      <td>这家 买 好几 次 说 实话 这是 次 苹果 越来越 肯定 斤 懒得 计较 生意 做 回头客...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51398</th>\n",
              "      <td>计算机</td>\n",
              "      <td>0</td>\n",
              "      <td>1发热厉害，用一个小时下面就烫手了，Dell的3000出头的笔记本一天也没这么热，有点害怕 ...</td>\n",
              "      <td>8</td>\n",
              "      <td>发热 厉害 小时 烫手 Dell 出头 笔记本 天 热 害怕 2机器 感觉 挺 单薄 塑料感...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28942</th>\n",
              "      <td>洗发水</td>\n",
              "      <td>1</td>\n",
              "      <td>非常好的商品，物流也快很好的商品</td>\n",
              "      <td>4</td>\n",
              "      <td>商品 物流 商品</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a572e99b-3e90-4cd1-8982-ee74d0f797c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a572e99b-3e90-4cd1-8982-ee74d0f797c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a572e99b-3e90-4cd1-8982-ee74d0f797c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取预处理的数据\n",
        "df = pd.read_csv('preprocessed_data.csv')"
      ],
      "metadata": {
        "id": "IJ6LcAOnUPAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "\n",
        "# 载入TF-IDF向量化器\n",
        "tfidf = load('/content/drive/MyDrive/tfidf_vectorizer.joblib')\n",
        "\n",
        "d2v_model = gensim.models.Doc2Vec.load('/content/drive/MyDrive/doc2vec_model')\n",
        "\n",
        "# 使用Doc2Vec模型对预处理后的文本进行向量化\n",
        "d2v_vectors = []\n",
        "for text in df['filtered_review']:\n",
        "    if isinstance(text, str):\n",
        "        vec = d2v_model.infer_vector(text.split())\n",
        "        d2v_vectors.append(vec)\n",
        "    else:\n",
        "        d2v_vectors.append(np.zeros(d2v_model.vector_size))  # 对于非字符串值，填充为零向量\n",
        "d2v_vectors = np.array(d2v_vectors)\n",
        "\n",
        "\n",
        "# 使用hstack将TF-IDF向量和Doc2Vec向量连接起来\n",
        "feature_matrix = hstack((tfidf_vectors, d2v_vectors))\n",
        "\n",
        "# 定义训练数据\n",
        "X_train = feature_matrix\n",
        "\n",
        "# 定义标签\n",
        "y_train = df['cat']\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, df['cat'], test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "\n",
        "# 载入训练好的LinearSVC模型\n",
        "model = load('/content/drive/MyDrive/linear_svc_model.joblib')\n",
        "\n",
        "# 进行预测\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 重置X_test的索引并创建一个新的DataFrame\n",
        "X_test_df = pd.DataFrame(X_test.toarray())\n",
        "X_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 创建一个新的数据框存储预测结果\n",
        "df_predicted = pd.DataFrame({'review': df['review'].values[X_test_df.index], 'predicted_category': predictions})\n",
        "\n",
        "# 输出预测结果\n",
        "print(df_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LRQZblYBlI_",
        "outputId": "e5b59fbe-c637-4a6c-b991-549cd400b723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review predicted_category\n",
            "0      ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...                 平板\n",
            "1      作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...                洗发水\n",
            "2      作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...                 平板\n",
            "3      作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...                 平板\n",
            "4      作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...                计算机\n",
            "...                                                  ...                ...\n",
            "12550                                 直接不能用，刚来点没反应，屏幕不能用                 酒店\n",
            "12551            收到了，有点后悔，除了硬件升级之外，外观比x1丑太多了，无比丑的大黑边，崩溃中                 蒙牛\n",
            "12552                                           一般，还没给赠品                 酒店\n",
            "12553  京东描述带手机卡的分辨率是1920×1080，结果只有1280×800，多花这些钱不是为了能...                 衣服\n",
            "12554                                   刚拿到手 内存一半就没了 太坑了                 蒙牛\n",
            "\n",
            "[12555 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# 进行预测\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 计算准确率\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# 计算召回率\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# 计算精确率\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# 计算F1分数\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# 创建包含预测结果的 DataFrame，仅使用测试数据集的索引\n",
        "df_results = pd.DataFrame({'Review': df['review'].values[X_test_df.index], 'Predicted_Category': predictions, 'Actual_Category': y_test})\n",
        "\n",
        "# 将预测结果分为预测正确和预测错误的两个数据框，仅使用测试数据集的索引\n",
        "correct_predictions = df_results[df_results['Predicted_Category'] == df_results['Actual_Category']]\n",
        "incorrect_predictions = df_results[df_results['Predicted_Category'] != df_results['Actual_Category']]\n",
        "\n",
        "# 将预测正确和预测错误的结果保存为 Excel 文件\n",
        "correct_predictions.to_excel('correct_predictions.xlsx', index=False)\n",
        "incorrect_predictions.to_excel('incorrect_predictions.xlsx', index=False)\n",
        "\n",
        "# 下载文件到本地\n",
        "files.download('correct_predictions.xlsx')\n",
        "files.download('incorrect_predictions.xlsx')\n",
        "\n",
        "# 输出指标结果\n",
        "print(\"准确率:\", accuracy)\n",
        "print(\"召回率:\", recall)\n",
        "print(\"精确率:\", precision)\n",
        "print(\"F1分数:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "VRyv3jGnRJ1f",
        "outputId": "a95f596c-f88b-4a10-82fc-75bc027fd8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c0480f04-6926-4381-b3ed-8a4ba16ad133\", \"correct_predictions.xlsx\", 1429081)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3948ebb3-7500-4b6c-974f-80c85c0ca641\", \"incorrect_predictions.xlsx\", 229510)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "准确率: 0.8615690959776982\n",
            "召回率: 0.8615690959776982\n",
            "精确率: 0.8658133236697655\n",
            "F1分数: 0.862647410826731\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}